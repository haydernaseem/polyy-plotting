import os
import json
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio
import warnings
warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ TensorFlow Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†
TENSORFLOW_AVAILABLE = False
LSTM_FORECASTING_AVAILABLE = False

try:
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from sklearn.preprocessing import MinMaxScaler
    import tensorflow as tf
    TENSORFLOW_AVAILABLE = True
    LSTM_FORECASTING_AVAILABLE = True
    logger.info("âœ… TensorFlow and scikit-learn imported successfully")
except ImportError as e:
    logger.warning(f"âš ï¸ TensorFlow/scikit-learn not available: {e}")
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø¯Ø§Ø¦Ù„ Ø¨Ø³ÙŠØ·Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± TensorFlow
    try:
        from sklearn.preprocessing import MinMaxScaler
        logger.info("âœ… scikit-learn available for basic scaling")
    except ImportError:
        logger.warning("âš ï¸ scikit-learn also not available")

app = Flask(__name__)

# ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CORS Ø§Ù„Ù…ÙˆØ³Ø¹Ø© Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª
CORS(app, origins=[
    "https://petroai-web.web.app",
    "https://petroai-web.firebaseapp.com", 
    "https://petroai-iq.web.app",
    "https://petroai-iq.firebaseapp.com",
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:5000",
    "http://127.0.0.1:5000",
    "http://localhost:8080",
    "http://127.0.0.1:8080",
    "http://localhost:5500",
    "http://127.0.0.1:5500",
    "https://*.web.app",
    "https://*.firebaseapp.com"
])

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
app.config['ALLOWED_EXTENSIONS'] = {'csv', 'txt', 'xlsx', 'xls'}
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

# Ø¥Ø¶Ø§ÙØ© headers ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø¯ÙˆØ¯
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization,X-Requested-With')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    response.headers.add('Access-Control-Allow-Credentials', 'true')
    response.headers.add('Access-Control-Max-Age', '86400')  # 24 hours
    return response

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª OPTIONS (preflight) ÙŠØ¯ÙˆÙŠØ§Ù‹
@app.before_request
def handle_preflight():
    if request.method == "OPTIONS":
        response = jsonify({"status": "success"})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization,X-Requested-With')
        response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
        response.headers.add('Access-Control-Allow-Credentials', 'true')
        return response

class PolyYPlot:
    """ÙØ¦Ø© PolyY Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø·Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆØ±"""

    def __init__(self, title="PolyY Chart", template="plotly"):
        self.title = title
        self.template = template
        self.traces = []
        self.y_axes = []
        self.current_yaxis = 1

    def add_trace(self, x_data, y_data, name, kind="line", color=None, yaxis=None):
        """Ø¥Ø¶Ø§ÙØ© trace Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ø§Ù„Ø±Ø³Ù…"""
        try:
            if yaxis is None:
                yaxis = f"y{self.current_yaxis}"
                self.current_yaxis += 1

            # Ø¥Ù†Ø´Ø§Ø¡ trace Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙˆØ¹
            if kind == "line":
                trace = go.Scatter(
                    x=x_data,
                    y=y_data,
                    name=name,
                    line=dict(color=color),
                    yaxis=yaxis
                )
            elif kind == "scatter":
                trace = go.Scatter(
                    x=x_data,
                    y=y_data,
                    name=name,
                    mode='markers',
                    marker=dict(color=color),
                    yaxis=yaxis
                )
            elif kind == "area":
                trace = go.Scatter(
                    x=x_data,
                    y=y_data,
                    name=name,
                    fill='tozeroy',
                    line=dict(color=color),
                    yaxis=yaxis
                )
            elif kind == "bar":
                trace = go.Bar(
                    x=x_data,
                    y=y_data,
                    name=name,
                    marker=dict(color=color),
                    yaxis=yaxis
                )
            else:
                trace = go.Scatter(
                    x=x_data,
                    y=y_data,
                    name=name,
                    line=dict(color=color),
                    yaxis=yaxis
                )

            self.traces.append(trace)

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­ÙˆØ± Y Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¬Ø¯ÙŠØ¯Ø§Ù‹
            if yaxis not in self.y_axes:
                self.y_axes.append(yaxis)
                
            return True
        except Exception as e:
            logger.error(f"Error adding trace: {e}")
            return False

    def create_figure(self, width=1200, height=600):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ figure Ø£Ø³Ø§Ø³ÙŠ
            fig = go.Figure()

            # Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ traces
            for trace in self.traces:
                fig.add_trace(trace)

            # Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ®Ø·ÙŠØ· Ø§Ù„Ù…Ø­Ø§ÙˆØ±
            layout_updates = {
                'title': self.title,
                'template': self.template,
                'width': width,
                'height': height,
                'showlegend': True,
                'plot_bgcolor': 'rgba(0,0,0,0)',
                'paper_bgcolor': 'rgba(0,0,0,0)'
            }

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø§ÙˆØ± Y Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
            for i, yaxis in enumerate(self.y_axes):
                side = 'right' if i % 2 == 1 else 'left'
                position = 1.0 - (i * 0.15) if side == 'right' else None

                layout_updates[f'yaxis{i+1}'] = {
                    'title': f'Y{i+1}',
                    'side': side,
                    'position': position,
                    'overlaying': 'y' if i > 0 else None,
                    'showgrid': True,
                    'gridcolor': 'rgba(128,128,128,0.2)',
                    'zeroline': False
                }

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­ÙˆØ± X
            layout_updates['xaxis'] = {
                'showgrid': True,
                'gridcolor': 'rgba(128,128,128,0.2)',
                'zeroline': False
            }

            fig.update_layout(**layout_updates)
            return fig
        except Exception as e:
            logger.error(f"Error creating figure: {e}")
            return None


class LSTMForecaster:
    """ÙØ¦Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM"""
    
    def __init__(self, lookback=10, forecast_steps=10):
        self.lookback = lookback
        self.forecast_steps = forecast_steps
        self.scalers = {}
        self.models = {}
        
    def create_sequences(self, data, lookback):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªÙˆØ§Ù„ÙŠØ§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            X, y = [], []
            for i in range(lookback, len(data)):
                X.append(data[i-lookback:i])
                y.append(data[i])
            return np.array(X), np.array(y)
        except Exception as e:
            logger.error(f"Error creating sequences: {e}")
            return np.array([]), np.array([])
    
    def build_model(self, input_shape):
        """Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ LSTM"""
        try:
            model = Sequential([
                LSTM(50, return_sequences=True, input_shape=input_shape),
                Dropout(0.2),
                LSTM(50, return_sequences=True),
                Dropout(0.2),
                LSTM(50),
                Dropout(0.2),
                Dense(25),
                Dense(1)
            ])
            model.compile(optimizer='adam', loss='mse', metrics=['mae'])
            return model
        except Exception as e:
            logger.error(f"Error building model: {e}")
            return None
    
    def forecast(self, data_dict, x_col, y_cols, forecast_percentage=0.25):
        """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame
            df = pd.DataFrame(data_dict)
            
            if df.empty:
                return {'success': False, 'error': 'Empty dataset provided'}
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ (25% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
            total_length = len(df)
            forecast_steps = max(3, int(total_length * forecast_percentage))
            
            forecasts = {}
            historical_predictions = {}
            
            for y_col in y_cols:
                if y_col not in df.columns:
                    logger.warning(f"Column {y_col} not found in dataset")
                    continue
                    
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§
                y_data = pd.to_numeric(df[y_col], errors='coerce').dropna().values
                
                if len(y_data) < self.lookback + 5:
                    logger.warning(f"Insufficient data for {y_col}: {len(y_data)} points, need at least {self.lookback + 5}")
                    continue
                
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                try:
                    scaler = MinMaxScaler()
                    y_scaled = scaler.fit_transform(y_data.reshape(-1, 1)).flatten()
                except Exception as e:
                    logger.error(f"Error scaling data for {y_col}: {e}")
                    continue
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªÙˆØ§Ù„ÙŠØ§Øª
                X, y = self.create_sequences(y_scaled, self.lookback)
                
                if len(X) == 0:
                    logger.warning(f"No valid sequences created for {y_col}")
                    continue
                
                # Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                model = self.build_model((self.lookback, 1))
                if model is None:
                    continue
                
                try:
                    # ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹ (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ)
                    model.fit(X, y, epochs=50, batch_size=16, verbose=0, validation_split=0.2)
                    
                    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ (Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)
                    historical_pred = model.predict(X, verbose=0)
                    historical_pred = scaler.inverse_transform(historical_pred).flatten()
                    
                    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ
                    last_sequence = y_scaled[-self.lookback:].reshape(1, self.lookback, 1)
                    future_predictions = []
                    
                    current_sequence = last_sequence.copy()
                    for _ in range(forecast_steps):
                        next_pred = model.predict(current_sequence, verbose=0)
                        future_predictions.append(next_pred[0, 0])
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ØªÙˆØ§Ù„ÙŠØ© Ø¨Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
                        current_sequence = np.roll(current_sequence, -1, axis=1)
                        current_sequence[0, -1, 0] = next_pred[0, 0]
                    
                    future_predictions = scaler.inverse_transform(
                        np.array(future_predictions).reshape(-1, 1)
                    ).flatten()
                    
                    forecasts[y_col] = future_predictions.tolist()
                    historical_predictions[y_col] = historical_pred.tolist()
                    self.scalers[y_col] = scaler
                    self.models[y_col] = model
                    
                    logger.info(f"âœ… Successfully forecasted {y_col} - {forecast_steps} steps")
                    
                except Exception as e:
                    logger.error(f"Error in model training/prediction for {y_col}: {e}")
                    continue
            
            if not forecasts:
                return {'success': False, 'error': 'No successful forecasts generated for any column'}
            
            return {
                'success': True,
                'forecasts': forecasts,
                'historical_predictions': historical_predictions,
                'forecast_steps': forecast_steps,
                'lookback': self.lookback
            }
            
        except Exception as e:
            logger.error(f"Forecasting error: {e}")
            return {
                'success': False,
                'error': f'Forecasting error: {str(e)}'
            }


class SimpleForecaster:
    """ÙØ¦Ø© ØªÙ†Ø¨Ø¤ Ø¨Ø³ÙŠØ·Ø© Ø¨Ø¯ÙˆÙ† TensorFlow"""
    
    def __init__(self, forecast_steps=10):
        self.forecast_steps = forecast_steps
        
    def simple_forecast(self, data_dict, x_col, y_cols, forecast_percentage=0.25):
        """ØªÙ†Ø¨Ø¤ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ"""
        try:
            df = pd.DataFrame(data_dict)
            
            if df.empty:
                return {'success': False, 'error': 'Empty dataset provided'}
            
            total_length = len(df)
            forecast_steps = max(3, int(total_length * forecast_percentage))
            
            forecasts = {}
            
            for y_col in y_cols:
                if y_col not in df.columns:
                    continue
                    
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§
                y_data = pd.to_numeric(df[y_col], errors='coerce').dropna().values
                
                if len(y_data) < 5:
                    continue
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ Ø¨Ø³ÙŠØ· Ù„Ù„ØªÙ†Ø¨Ø¤
                window_size = min(5, len(y_data) // 2)
                if window_size < 2:
                    window_size = 2
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ
                moving_avg = np.convolve(y_data, np.ones(window_size)/window_size, mode='valid')
                
                if len(moving_avg) < 2:
                    continue
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø®ÙŠØ±
                last_trend = moving_avg[-1] - moving_avg[-2] if len(moving_avg) > 1 else 0
                last_value = y_data[-1]
                
                future_predictions = []
                for i in range(forecast_steps):
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
                    next_value = last_value + last_trend * (1 + 0.1 * np.random.normal())
                    future_predictions.append(next_value)
                    last_value = next_value
                
                forecasts[y_col] = future_predictions
            
            if not forecasts:
                return {'success': False, 'error': 'No successful forecasts generated'}
            
            return {
                'success': True,
                'forecasts': forecasts,
                'forecast_steps': forecast_steps,
                'method': 'simple_moving_average',
                'message': 'Used simple moving average (TensorFlow not available)'
            }
            
        except Exception as e:
            logger.error(f"Simple forecasting error: {e}")
            return {'success': False, 'error': f'Simple forecasting error: {str(e)}'}


def allowed_file(filename):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']


def read_data_file(file):
    """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯Ø¹Ù… Ù„Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    filename = file.filename.lower()
    
    try:
        if filename.endswith('.csv'):
            return pd.read_csv(file)
        elif filename.endswith('.txt'):
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ù†ØµÙŠ Ø¨ÙØ§ØµÙ„ ØªØ¨ÙˆÙŠØ¨ Ø£Ùˆ ÙØ§ØµÙ„Ø©
            try:
                return pd.read_csv(file, sep='\t')
            except:
                file.seek(0)  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø¤Ø´Ø±
                return pd.read_csv(file, sep=',')
        elif filename.endswith(('.xlsx', '.xls')):
            return pd.read_excel(file)
        else:
            raise ValueError("Unsupported file format")
    except Exception as e:
        logger.error(f"Error reading file {filename}: {e}")
        raise ValueError(f"Error reading file: {str(e)}")


@app.route('/health', methods=['GET'])
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    return jsonify({
        'status': 'healthy',
        'service': 'PolyY Plotting API',
        'version': '2.1',
        'endpoints': {
            'upload': '/upload (POST) - Upload data file',
            'create_plot': '/create_plot (POST) - Create plot from JSON',
            'create_plot_from_file': '/create_plot_from_file (POST) - Create plot directly from file',
            'forecast': '/forecast (POST) - LSTM forecasting',
            'example_data': '/example_data (GET) - Get sample data'
        },
        'supported_formats': ['CSV', 'TXT', 'Excel (XLSX, XLS)'],
        'supported_plot_types': ['line', 'scatter', 'area', 'bar'],
        'features': {
            'tensorflow_available': TENSORFLOW_AVAILABLE,
            'lstm_forecasting': LSTM_FORECASTING_AVAILABLE,
            'multi_y_axis': True,
            'forecasting': True
        }
    })


@app.route('/upload', methods=['POST'])
def upload_file():
    """Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        if not allowed_file(file.filename):
            return jsonify({'error': 'Invalid file type. Please upload CSV, TXT, or Excel files.'}), 400

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = read_data_file(file)

        if df.empty:
            return jsonify({'error': 'The uploaded file is empty'}), 400

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©
        df_clean = df.copy()
        numeric_columns = df_clean.select_dtypes(include=[np.number]).columns.tolist()

        for col in numeric_columns:
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        all_columns = df_clean.columns.tolist()

        # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø£ÙˆÙ„ 10 ØµÙÙˆÙ)
        preview_data = []
        for _, row in df_clean.head(10).iterrows():
            row_data = {}
            for col in all_columns:
                value = row[col]
                if pd.isna(value):
                    row_data[col] = None
                elif isinstance(value, (int, float)):
                    row_data[col] = float(value)
                else:
                    row_data[col] = str(value)
            preview_data.append(row_data)

        # Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
        column_stats = {}
        for col in numeric_columns:
            if col in df_clean.columns:
                col_data = df_clean[col].dropna()
                if len(col_data) > 0:
                    column_stats[col] = {
                        'min': float(col_data.min()),
                        'max': float(col_data.max()),
                        'mean': float(col_data.mean()),
                        'std': float(col_data.std()),
                        'count': int(len(col_data))
                    }

        response = {
            'success': True,
            'columns': all_columns,
            'numeric_columns': numeric_columns,
            'preview': preview_data,
            'total_rows': len(df_clean),
            'total_columns': len(all_columns),
            'column_stats': column_stats,
            'message': f'Successfully loaded {len(df_clean)} rows with {len(all_columns)} columns'
        }

        logger.info(f"File uploaded successfully: {file.filename}, {len(df_clean)} rows")
        return jsonify(response)

    except Exception as e:
        logger.error(f"Error processing file: {e}")
        return jsonify({'error': f'Error processing file: {str(e)}'}), 500


@app.route('/create_plot', methods=['POST'])
def create_plot():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· PolyY Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª JSON"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({'error': 'No data provided'}), 400

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        title = data.get('title', 'PolyY Chart')
        template = data.get('template', 'plotly')
        width = data.get('width', 1200)
        height = data.get('height', 600)
        traces_data = data.get('traces', [])

        if not traces_data:
            return jsonify({'error': 'No traces data provided'}), 400

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for i, trace in enumerate(traces_data):
            if 'x_data' not in trace or 'y_data' not in trace:
                return jsonify({'error': f'Trace {i+1} missing x_data or y_data'}), 400

            if len(trace['x_data']) != len(trace['y_data']):
                return jsonify({'error': f'Trace {i+1} has mismatched x and y data lengths'}), 400

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· PolyY
        plotter = PolyYPlot(title=title, template=template)

        # Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ traces
        successful_traces = 0
        for trace_config in traces_data:
            success = plotter.add_trace(
                x_data=trace_config['x_data'],
                y_data=trace_config['y_data'],
                name=trace_config.get('name', f'Trace {successful_traces + 1}'),
                kind=trace_config.get('kind', 'line'),
                color=trace_config.get('color'),
                yaxis=trace_config.get('yaxis')
            )
            if success:
                successful_traces += 1

        if successful_traces == 0:
            return jsonify({'error': 'No valid traces could be created'}), 400

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙƒÙ„
        fig = plotter.create_figure(width=width, height=height)
        
        if fig is None:
            return jsonify({'error': 'Failed to create plot figure'}), 500

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ JSON Ù„Ù„ØªÙØ§Ø¹Ù„
        plot_json = fig.to_json()

        response = {
            'success': True,
            'plot_json': json.loads(plot_json),
            'traces_count': successful_traces,
            'y_axes_count': len(plotter.y_axes),
            'title': title,
            'message': f'Successfully created plot with {successful_traces} traces and {len(plotter.y_axes)} Y-axes'
        }

        logger.info(f"Plot created successfully: {title}, {successful_traces} traces")
        return jsonify(response)

    except Exception as e:
        logger.error(f"Error creating plot: {e}")
        return jsonify({'error': f'Error creating plot: {str(e)}'}), 500


@app.route('/create_plot_from_file', methods=['POST'])
def create_plot_from_file():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file uploaded'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = read_data_file(file)

        if df.empty:
            return jsonify({'error': 'The uploaded file is empty'}), 400

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø³Ù… Ù…Ù† form data
        title = request.form.get('title', 'PolyY Chart')
        template = request.form.get('template', 'plotly')
        x_column = request.form.get('x_column')
        y_columns = request.form.getlist('y_columns[]')
        kinds = request.form.getlist('kinds[]')
        colors = request.form.getlist('colors[]')
        names = request.form.getlist('names[]')

        if not x_column:
            return jsonify({'error': 'X column is required'}), 400

        if not y_columns:
            return jsonify({'error': 'At least one Y column is required'}), 400

        if x_column not in df.columns:
            return jsonify({'error': f'X column "{x_column}" not found in data'}), 400

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· PolyY
        plotter = PolyYPlot(title=title, template=template)

        # Ø¥Ø¶Ø§ÙØ© traces
        valid_traces = 0
        x_data = df[x_column].tolist()

        for i, y_col in enumerate(y_columns):
            if y_col and y_col in df.columns:
                y_data = pd.to_numeric(df[y_col], errors='coerce').dropna().tolist()

                if len(y_data) > 0:
                    # ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø·ÙˆÙ„ Ø¨ÙŠÙ† X Ùˆ Y
                    min_length = min(len(x_data), len(y_data))
                    success = plotter.add_trace(
                        x_data=x_data[:min_length],
                        y_data=y_data[:min_length],
                        name=names[i] if i < len(names) and names[i] else y_col,
                        kind=kinds[i] if i < len(kinds) and kinds[i] else 'line',
                        color=colors[i] if i < len(colors) and colors[i] else None
                    )
                    if success:
                        valid_traces += 1

        if valid_traces == 0:
            return jsonify({'error': 'No valid numeric data found in the specified Y columns'}), 400

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙƒÙ„
        fig = plotter.create_figure()
        if fig is None:
            return jsonify({'error': 'Failed to create plot figure'}), 500
            
        plot_json = fig.to_json()

        response = {
            'success': True,
            'plot_json': json.loads(plot_json),
            'traces_count': valid_traces,
            'x_column': x_column,
            'y_columns': [y_col for y_col in y_columns if y_col in df.columns],
            'message': f'Successfully created plot from file with {valid_traces} traces'
        }

        logger.info(f"Plot from file created: {file.filename}, {valid_traces} traces")
        return jsonify(response)

    except Exception as e:
        logger.error(f"Error creating plot from file: {e}")
        return jsonify({'error': f'Error creating plot from file: {str(e)}'}), 500


@app.route('/forecast', methods=['POST'])
def forecast():
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM Ø£Ùˆ Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({'error': 'No data provided'}), 400

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_dict = data.get('data', {})
        x_col = data.get('x_column')
        y_cols = data.get('y_columns', [])
        chart_type = data.get('chart_type', 'line')

        if not data_dict:
            return jsonify({'error': 'No data provided for forecasting'}), 400

        if not x_col:
            return jsonify({'error': 'X column is required'}), 400

        if not y_cols:
            return jsonify({'error': 'At least one Y column is required'}), 400

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù… Ù‡Ùˆ line chart
        if chart_type != 'line':
            return jsonify({'error': 'Forecasting is only available for line charts'}), 400

        result = None
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
        if LSTM_FORECASTING_AVAILABLE:
            logger.info("Using LSTM for forecasting")
            forecaster = LSTMForecaster(lookback=10, forecast_steps=10)
            result = forecaster.forecast(data_dict, x_col, y_cols)
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©
            logger.info("Using simple forecasting (LSTM not available)")
            simple_forecaster = SimpleForecaster(forecast_steps=10)
            result = simple_forecaster.simple_forecast(data_dict, x_col, y_cols)

        if not result['success']:
            return jsonify({'error': result['error']}), 400

        response = {
            'success': True,
            'forecasts': result['forecasts'],
            'forecast_steps': result['forecast_steps'],
            'lookback': result.get('lookback', 0),
            'method': result.get('method', 'lstm'),
            'message': result.get('message', f'Successfully generated forecasts for {len(result["forecasts"])} columns')
        }

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
        if 'historical_predictions' in result:
            response['historical_predictions'] = result['historical_predictions']

        logger.info(f"Forecast completed: {len(result['forecasts'])} columns, {result['forecast_steps']} steps")
        return jsonify(response)

    except Exception as e:
        logger.error(f"Error generating forecasts: {e}")
        return jsonify({'error': f'Error generating forecasts: {str(e)}'}), 500


@app.route('/example_data', methods=['GET'])
def get_example_data():
    """Ø¥Ø±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø«Ø§Ù„ÙŠÙ‡ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø«Ø§Ù„ÙŠÙ‡ Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
        np.random.seed(42)  # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø«Ø§Ø¨ØªØ©

        timestamps = pd.date_range(
            '2024-01-01', periods=100, freq='H').strftime('%Y-%m-%d %H:%M:%S').tolist()

        # Ø¨ÙŠØ§Ù†Ø§Øª Ø·Ø§Ù‚Ø© Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ© Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        time_index = np.arange(100)

        example_data = {
            'timestamp': timestamps,
            'power_kwh': (50 + 10 * np.sin(time_index * 0.1) + np.random.normal(0, 3, 100)).tolist(),
            'voltage_v': (220 + 5 * np.cos(time_index * 0.05) + np.random.normal(0, 1, 100)).tolist(),
            'current_a': (15 + 3 * np.sin(time_index * 0.08) + np.random.normal(0, 0.5, 100)).tolist(),
            'temperature_c': (25 + 2 * np.sin(time_index * 0.03) + np.random.normal(0, 0.3, 100)).tolist(),
            'reactive_power_kvar': (10 + 2 * np.cos(time_index * 0.06) + np.random.normal(0, 0.4, 100)).tolist(),
            'efficiency': (0.85 + 0.1 * np.sin(time_index * 0.04) + np.random.normal(0, 0.02, 100)).tolist()
        }

        return jsonify({
            'success': True,
            'data': example_data,
            'description': 'Sample energy consumption data with 100 time points',
            'columns': {
                'timestamp': 'Time stamps',
                'power_kwh': 'Power consumption in kWh',
                'voltage_v': 'Voltage in volts',
                'current_a': 'Current in amperes',
                'temperature_c': 'Temperature in Celsius',
                'reactive_power_kvar': 'Reactive power in kVAR',
                'efficiency': 'System efficiency ratio'
            }
        })
    except Exception as e:
        logger.error(f"Error generating example data: {e}")
        return jsonify({'error': f'Error generating example data: {str(e)}'}), 500


@app.route('/test_plot', methods=['GET'])
def test_plot():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    try:
        # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        x_data = list(range(1, 101))

        plotter = PolyYPlot(title="Test PolyY Plot", template="plotly_dark")

        # Ø¥Ø¶Ø§ÙØ© Ø¹Ø¯Ø© traces Ø¨Ø£Ù†Ù…Ø§Ø· Ù…Ø®ØªÙ„ÙØ©
        traces_added = 0
        traces_added += 1 if plotter.add_trace(
            x_data=x_data,
            y_data=[i + np.random.normal(0, 2) for i in x_data],
            name="Linear Trend",
            kind="line",
            color="#FF6B6B"
        ) else 0

        traces_added += 1 if plotter.add_trace(
            x_data=x_data,
            y_data=[50 * np.sin(i * 0.1) + np.random.normal(0, 5) for i in x_data],
            name="Sine Wave",
            kind="scatter",
            color="#4ECDC4"
        ) else 0

        traces_added += 1 if plotter.add_trace(
            x_data=x_data,
            y_data=[i ** 0.5 * 10 + np.random.normal(0, 3) for i in x_data],
            name="Square Root",
            kind="area",
            color="#45B7D1"
        ) else 0

        if traces_added == 0:
            return jsonify({'error': 'Failed to create test traces'}), 500

        fig = plotter.create_figure()
        if fig is None:
            return jsonify({'error': 'Failed to create test plot figure'}), 500
            
        plot_json = fig.to_json()

        return jsonify({
            'success': True,
            'plot_json': json.loads(plot_json),
            'message': 'Test plot generated successfully'
        })

    except Exception as e:
        logger.error(f"Error generating test plot: {e}")
        return jsonify({'error': f'Error generating test plot: {str(e)}'}), 500


@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint not found'}), 404


@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({'error': 'Internal server error'}), 500


@app.errorhandler(413)
def too_large(error):
    return jsonify({'error': 'File too large'}), 413


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"ğŸš€ Starting PolyY Plotting API on port {port}")
    logger.info(f"ğŸ“Š TensorFlow Available: {TENSORFLOW_AVAILABLE}")
    logger.info(f"ğŸ¤– LSTM Forecasting Available: {LSTM_FORECASTING_AVAILABLE}")
    logger.info(f"ğŸ”§ Debug Mode: {debug_mode}")
    
    app.run(host='0.0.0.0', port=port, debug=debug_mode)
